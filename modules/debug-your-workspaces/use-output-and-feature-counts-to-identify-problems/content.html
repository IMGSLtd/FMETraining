<h2 id="learning-objectives">
  <span>Learning Objectives</span>
</h2>
<p>After completing this unit, you’ll be able to:</p>
<ul>
  <li>Describe why debugging is an important skill.</li>
  <li><br /></li>
</ul>
<h2 id="resources">
  <span>Resources</span>
</h2>
<ul>
  <li>Starting workspace<ul>
      <li>Commit to FMEData using the branch of the current release year.</li>
      <li>Place in Workspaces/TheNameOfYourTrail</li>
      <li>Name workspaces in all lowercase with - replacing spaces, e.g. Exercise: Create and Modify Attributes becomes exercise-create-and-modify-attributes.fmw.</li>
      <li>Workspaces committed to FMEData will automatically appear in S3.</li>
      <li>The S3 URL follows this pattern: <a href="https://s3.amazonaws.com/FMEData/FMEData2020/Workspaces/IntegrateYourDataWithTheFMEPlatform/edit-your-datas-schema.fmw" rel="noreferrer noopener" target="_blank">https://s3.amazonaws.com/FMEData/FMEData2020/Workspaces/IntegrateYourDataWithTheFMEPlatform/edit-your-datas-schema.fmw</a></li>
      <li>Completed (finished) workspaces should not be linked to in the outline, but should be committed to Workspaces/InstructorUse/Workspaces/FMEAcademy. These should have -complete appended to their filenames, e.g. exercise-join-your-spatial-data-complete.fmw.</li>
    </ul>
  </li>
</ul>
<h2 id="inspecting-output">
  <span>Inspecting Output</span>
</h2>
<p>Even if a workspace ran to completion without warnings or errors, it does not follow that the output matches what is expected or required. For whatever reason, the workspace may be producing data in the wrong manner. We can determine this by inspecting the translation output.</p>
<p>Inspecting the output is merely a case of viewing it in either Visual Preview or in the application in which the data is intended to be used.</p>
<p>As noted already in this manual, a number of different aspects of data may be inspected, including the following:</p>
<ul>
  <li>Format: Is the data in the expected format?</li>
  <li>Schema: Is the data subdivided into the correct layers, categories, or classes?</li>
  <li>Geometry: Is the geometry in the correct spatial location? Are the geometry types correct?</li>
  <li>Symbology: Is the color, size, and style of each feature correct?</li>
  <li>Attributes: Are all the required attributes present? Are all integrity rules being followed?</li>
  <li>Quantity: Does the data contain the correct number of features?</li>
  <li>Output: Has the translation process restructured the data as expected?</li>
</ul>
<p>It should be straightforward to check a dataset and see if any of its components are incorrect.</p>
<p> </p>
<p>Note</p>
<p>This stage is solely to determine if there are any problems.</p>
<p> </p>
<p>If there are no problems, then we can be satisfied the translation was a success.</p>
<p>If there are problems, we should go on to determine where the problem occurred. It's important not to jump to conclusions at this point. The fact that the output is incorrect does not tell us where that issue was introduced.</p>
<h2 id="feature-counts">
  <span>Feature Counts</span>
</h2>
<p>A workspace feature count refers to the numbers shown on each connection once a translation is complete:</p>
<p><img src="images/0-cfafefa-c-769-41-ff-9005-39-c-3-d-4523507.png" width="624" height="287" class="image image-block image-center" /></p>
<p>Once an error or problem has been determined to exist, feature counts help us identify where that problem occurred.</p>
<p>In the above screenshot, if the Clipper output were incorrect, then you would inspect the prior feature counts to see if any counts looked wrong (perhaps you know that there are seven neighborhoods, but the feature count shows only six).</p>
<h2 id="incorrect-output">
  <span>Incorrect Output</span>
</h2>
<p>When the number of output features is incorrect, then there are several things to check.</p>
<p>If you get zero output, and the feature counts show that all features entered a transformer, but none emerged, then you can be fairly confident that the transformer is the cause of the problem:</p>
<p><img src="images/f-21-e-6901-edf-4-4-e-6-e-be-71-88405-a-0-de-9-fc.png" width="454" height="304" class="image image-block image-center" /></p>
<p>Here, for example, 80 features enter the Clipper transformer (to be clipped against a single boundary) but none emerged. The Clipper transformer is almost certainly the cause of any incorrect output.</p>
<p>The data is not rejected as invalid; it merely does not pass the test expected. It's possible that Clipper and Clippee don't occupy the same coordinate system; hence, one does not fall inside the other.</p>
<p>Turning on feature caching helps to confirm this to be the case:</p>
<p><img src="images/d-88-ab-642-3674-4-edf-b-4-f-9-adcb-2-d-5-a-9-a-73.png" width="442" height="292" class="image image-block image-center" /></p>
<p>Alternatively - and this is a common cause of missing features - the author has connected the wrong output port! For example, this user has connected the StatisticsCalculator Summary output port, when they really wanted the Complete port connected:</p>
<p><img src="images/5-c-9900-c-7-55-fa-44-e-3-8-f-82-7-f-388-d-8-c-00-fb.png" width="414" height="174" class="image image-block image-center" /></p>
<p>Again feature caching gives us a clue to what port we should connect.</p>
<h2 id="rejected-features">
  <span>Rejected Features</span>
</h2>
<p>Sometimes when features go missing, they are being rejected by a transformer. Many transformers include a &lt;Rejected&gt; port to output these invalid features:</p>
<p><img src="images/11652-c-6-d-77-c-4-43-d-8-ab-3-f-1-e-48-af-41-f-8-c-7.png" width="383" height="148" class="image image-block image-center" /></p>
<p>Remember, features are automatically counted and stored on a &lt;Rejected&gt; port, even if feature caching is turned off.</p>
<p>As an additional benefit, the rejected features will often include a rejection code attribute:</p>
<p><img src="images/2-bee-951-d-bdb-9-4340-8-a-83-d-015-d-1-b-60-c-4-e.png" width="605" height="218" class="image image-block image-center" /></p>